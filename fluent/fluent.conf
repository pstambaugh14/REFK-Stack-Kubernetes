# AUTOMATICALLY GENERATED
# DO NOT EDIT THIS FILE DIRECTLY, USE /templates/conf/fluent.conf.erb

@include "#{ENV['FLUENTD_SYSTEMD_CONF'] || 'systemd'}.conf"
@include "#{ENV['FLUENTD_PROMETHEUS_CONF'] || 'prometheus'}.conf"
@include kubernetes.conf
@include conf.d/*.conf

<match **>
#  @type redis-store
  @type redis
#  host REDIS_HOST_ADDRESS(string, all , localhost)
#  host "#{ENV['FLUENTD_REDISSTORE_HOST']" 
  host redis.kube-logging.svc.cluster.local
#  port REDIS_PORT(int, all, 6379)
#  port "#{ENV['FLUENTD_REDISSTORE_PORT']"
  port 6379
#  db_number REDIS_DB_NUMBER(int, all , nil)
#  db_number 0
  db 0
#  timeout TIMEOUT(float, all , 5.0)
  timeout 15
#  request_timeout 15s
#  key_prefix prefix_(string, all, '')
#  key_suffix _suffix(string, all , '')
#  store_type zset(zset|set|list|string, all, zset)
  store_type list
#  key_name key(string, all, nil)
#  key_name logstash
  key logstash
#  score_name score(string, all , nil)
#  value_name value(string, all, nill)
#  key_expire 604800(int, all, nil)
#  value_expire 86400(int , zset, nil)
#  value_length 100(int, zset|list, nil)
#  order asc(asc|desc, zset/list, nil)
#</match>
#<match pattern>
#  @type forward
#  host "#{ENV['FLUENT_FOWARD_HOST']}" #redis.kube-logging.svc.cluster.local
#  port "#{ENV['FLUENT_FOWARD_PORT']}" #6379
#  db_number 0
#  timeout TIMEOUT 5.0
#  key_prefix prefix_(string, all, '')
#  key_suffix _suffix(string, all , '')
#  store_type list
#  key_name logstash
#  score_name score(string, all , nil)
#  value_name value(string, all, nill)
#  key_expire 604800(int, all, nil)
#  value_expire 86400(int , zset, nil)
#  value_length 100(int, zset|list, nil)
#  order asc(asc|desc, zset/list, nil)
#</match>

#<server>
#  name redis
#  host redis.kube-logging.svc.cluster.local
#  port 6379
#  weight 60
#</server>

# use hiredis for better performance
# this configuration requires "gem install hiredis"
#<match pattern>
#  type redisstore
#  driver hiredis
#  ...
#</match>

#   @type elasticsearch
#   @type redisstore
#   @id out_es
#   @log_level info
#   include_tag_key true
#   host "#{ENV['FLUENT_ELASTICSEARCH_HOST']}"
#   port "#{ENV['FLUENT_ELASTICSEARCH_PORT']}"
#   path "#{ENV['FLUENT_ELASTICSEARCH_PATH']}"
#   scheme "#{ENV['FLUENT_ELASTICSEARCH_SCHEME'] || 'http'}"
#   ssl_verify "#{ENV['FLUENT_ELASTICSEARCH_SSL_VERIFY'] || 'true'}"
#   ssl_version "#{ENV['FLUENT_ELASTICSEARCH_SSL_VERSION'] || 'TLSv1'}"
#   user "#{ENV['FLUENT_ELASTICSEARCH_USER']}"
#   password "#{ENV['FLUENT_ELASTICSEARCH_PASSWORD']}"
#   reload_connections "#{ENV['FLUENT_ELASTICSEARCH_RELOAD_CONNECTIONS'] || 'false'}"
#   reconnect_on_error "#{ENV['FLUENT_ELASTICSEARCH_RECONNECT_ON_ERROR'] || 'true'}"
#   reload_on_failure "#{ENV['FLUENT_ELASTICSEARCH_RELOAD_ON_FAILURE'] || 'true'}"
#   log_es_400_reason "#{ENV['FLUENT_ELASTICSEARCH_LOG_ES_400_REASON'] || 'false'}"
#   logstash_prefix "#{ENV['FLUENT_ELASTICSEARCH_LOGSTASH_PREFIX'] || 'logstash'}"
#   logstash_format "#{ENV['FLUENT_ELASTICSEARCH_LOGSTASH_FORMAT'] || 'true'}"
#   index_name "#{ENV['FLUENT_ELASTICSEARCH_LOGSTASH_INDEX_NAME'] || 'logstash'}"
#   type_name "#{ENV['FLUENT_ELASTICSEARCH_LOGSTASH_TYPE_NAME'] || 'fluentd'}"
#   <buffer>
#     flush_thread_count "#{ENV['FLUENT_ELASTICSEARCH_BUFFER_FLUSH_THREAD_COUNT'] || '8'}"
#     flush_thread_count "#{ENV['FLUENT_ELASTICSEARCH_BUFFER_FLUSH_THREAD_COUNT'] || '8'}"
#     flush_interval "#{ENV['FLUENT_ELASTICSEARCH_BUFFER_FLUSH_INTERVAL'] || '5s'}"
#     chunk_limit_size "#{ENV['FLUENT_ELASTICSEARCH_BUFFER_CHUNK_LIMIT_SIZE'] || '2M'}"
#     queue_limit_length "#{ENV['FLUENT_ELASTICSEARCH_BUFFER_QUEUE_LIMIT_LENGTH'] || '32'}"
#     retry_max_interval "#{ENV['FLUENT_ELASTICSEARCH_BUFFER_RETRY_MAX_INTERVAL'] || '30'}"
#     retry_forever true
#   </buffer>
</match>
